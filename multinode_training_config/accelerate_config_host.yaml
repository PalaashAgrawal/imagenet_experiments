#using WS3 as the main node and WS1 as sub node
#see accelerate config documentation here: https://huggingface.co/docs/accelerate/usage_guides/explore
#using port 8900 for training


compute_environment: LOCAL_MACHINE
deepspeed_config: {}
distributed_type: MULTI_GPU
downcast_bf16: 'no'
dynamo_backend: 'NO'
fsdp_config: {}
gpu_ids: all
machine_rank: 0
main_process_ip: 172.20.85.67
main_process_port: 8900
main_training_function: main
megatron_lm_config: {}
mixed_precision: 'no'
num_machines: 2
num_processes: 8
rdzv_backend: static
same_network: true
use_cpu: false
  